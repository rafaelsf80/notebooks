---
keywords: fastai
description: Ejemplo sencillo de Federated Learning con TFF usando MNIST.
title: "Federated Learning: ejemplo sencillo"
toc: true 
badges: true 
comments: true
categories: ["Computer Vision"]
image: images/tensorflow.png
nb_path: _notebooks/2021-01-16-tensorflow-federated.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-01-16-tensorflow-federated.ipynb
-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Introducci&#243;n">1. Introducci&#243;n<a class="anchor-link" href="#1.-Introducci&#243;n"> </a></h2><p>Este tutorial usa el dataset de MNIST con el API de alto nivel de TFF, llamado <strong>FL API</strong> (Federated Layer API) cuya clase principal es  <code>tff.learning</code>, la cual incluye interfaces de alto nivel para tareas típicas de federación como entrenamiento y otras.</p>
<p>Existe otra API de más bajo nivel, <strong>FC API</strong> (Federated Core API), que permite implementar tus propios algoritmos de federación.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Setup">2. Setup<a class="anchor-link" href="#2.-Setup"> </a></h2><p>Instalamos versiones concretas de TF y TFF, que deben ser compatibles entre ellas. Ver <a href="https://github.com/tensorflow/federated#compatibility">tabla</a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install --quiet --upgrade <span class="nv">tensorflow_federated</span><span class="o">==</span><span class="m">0</span>.17
<span class="o">!</span>pip install --quiet --upgrade <span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.3.0

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_federated</span> <span class="k">as</span> <span class="nn">tff</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tff</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>La instalación del paquete <code>nest_asyncio</code> evita errores de ejecución en los protocolos de federación en Jupyter (del tipo <em>"can not join a run while another loop is running"</em>):</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">nest_asyncio</span>
<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Carga-de-datos">3. Carga de datos<a class="anchor-link" href="#3.-Carga-de-datos"> </a></h2><p>Cargamos los datos. TFF ya tiene una clase para cargar datos y poder separarla en clientes.
El dataset que devuelve <code>load_data()</code> son instancias de <code>tff.simulation.ClientData</code>, un interfaz que permite escoger un conjunto de clientes, para posteriormente construir un <code>tf.data.Dataset</code> que represente los datos de un cliente, y así poder entrenar.</p>
<p>Nótese que este interfaz permite iterar sobre ID de clientes, pero en este tutorial sólo los estamos simulando. Los ID de clientes no se usan en el algoritmo de federación, sólo se usan para escoger los datos de cada cliente.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load simulation data.</span>
<span class="n">source</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tff</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">emnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">client_data</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">source</span><span class="o">.</span><span class="n">create_tf_dataset_for_client</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">client_ids</span><span class="p">[</span><span class="n">n</span><span class="p">])</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
      <span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;pixels&#39;</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">e</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
  <span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">client_ids</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Seleccionamos unos cuantos clientes que participarán en el entrenamiento:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Pick a subset of client devices to participate in training.</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">client_data</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">source</span><span class="o">.</span><span class="n">element_type_structure</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Construcci&#243;n-del-modelo">4. Construcci&#243;n del modelo<a class="anchor-link" href="#4.-Construcci&#243;n-del-modelo"> </a></h2><p>Usamos un modelo estándar de Keras, el cual debe paquetizarse dentro de la clase <code>tff.learning</code>.
Se usará la llamada <code>tff.learning.from_keras_model</code>, pasándole el modelo Keras original y los datos.</p>
<p><strong>Nota:</strong> no hay que compilar ahora. Las métricas, pérdidas y optimizadores se configuran más tarde.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Wrap a Keras model for use with TFF.</span>
<span class="k">def</span> <span class="nf">model_fn</span><span class="p">():</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,),</span>
                            <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">)</span>
  <span class="p">])</span>
  <span class="k">return</span> <span class="n">tff</span><span class="o">.</span><span class="n">learning</span><span class="o">.</span><span class="n">from_keras_model</span><span class="p">(</span>
      <span class="n">model</span><span class="p">,</span>
      <span class="n">input_spec</span><span class="o">=</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">element_spec</span><span class="p">,</span>
      <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(),</span>
      <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="5.-Simulaci&#243;n-y-evaluaci&#243;n">5. Simulaci&#243;n y evaluaci&#243;n<a class="anchor-link" href="#5.-Simulaci&#243;n-y-evaluaci&#243;n"> </a></h2><p>Ahora que tenemos el modelo empaquetado en una clase <code>tff.learning.Model</code> para usarlo en TFF, podemos ejecutar
al algoritmo <strong>Federated Averaging</strong> usando la función <code>tff.learning.build_federated_averaging_process</code>.</p>
<p>El argumento debe ser un constructor (como la <code>model_fn</code> de arriba), no una instancia, para que la construcción y compilado del modelo
lo pueda implementar TFF. Los detalles técnicos están en <a href="custom_federated_algorithms_1.ipynb">este tutorial</a>.</p>
<p>El algoritmo <strong>Federated Averaging</strong> tiene dos optimizadores:</p>
<ol>
<li><code>_client_optimizer_</code>: se usa para computar updates en cada cliente.  </li>
<li><code>_server_optimizer_</code>: aplica la media al modelo global en el servidor.</li>
</ol>
<p>Por tanto, la elección de los hiperparámeotrs de optimizador y learning rate serán distintos que los que se usan en el modelo Keras original de MNIST. Se recomienda empezar con SGD, con un learning rate pequeño.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Simulate a few rounds of training with the selected client devices.</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">tff</span><span class="o">.</span><span class="n">learning</span><span class="o">.</span><span class="n">build_federated_averaging_process</span><span class="p">(</span>
  <span class="n">model_fn</span><span class="p">,</span>
  <span class="n">client_optimizer_fn</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>TFF implementa el algoritmo de <a href="https://arxiv.org/abs/1602.05629">Federated Averaging</a> con dos computaciones empaquetadas en la clase <code>tff.templates.IterativeProcess</code>. Estas dos computaciones son <code>initialize</code> y <code>next</code>.</p>
<ol>
<li>La operación <code>initialize</code> es una función, como todas las computaciones federadas.
No usa argumentos, y devuelve un resultado: la representación del estado del proceso de Federated Averaging en el servidor.</li>
<li>La operación <code>next</code> es una función, y representa un ciclo completo de Federated Averaging, que consiste en desplegar el estado del servidor (incluyendo el modelo inicial) a los clientes, entrenamiento en los clientes, recogida de parámetros de vuelta, y generación de un modelo nuevo en el servidor.</li>
</ol>
<p>Actualmente el algoritmo se soporta en local por ahora (se ejecuta toda en una máquina).</p>
<p>Se puede pensar en <code>next</code> como este flujo:</p>
<p><code>SERVER_STATE, FEDERATED_DATA -&gt; SERVER_STATE, TRAINING_METRICS</code></p>
<p>Es decir, <code>next</code> no es una función que se ejecuta en un servidor, sino que se ejecuta de manera distribuída, con un input del servidor (<code>SERVER_STATE</code>), y unas contribuciones de cada cliente con sus propios datos locales.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
  <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">next</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">train_data</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>En este tutorial, se deberían escoger clientes aleatoriamente, pero reusamos los clientes para una covergencia más rápida. Las pérdidas deberían disminuir después de cada ciclo de entrenamiento federado, mostrando que el modelo converge.</p>

</div>
</div>
</div>
</div>
 

