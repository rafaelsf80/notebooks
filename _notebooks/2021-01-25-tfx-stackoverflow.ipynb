{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "components_keras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "wdeKOEkv1Fe8"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "Python 3.8.2 64-bit",
      "display_name": "Python 3.8.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23R0Z9RojXYW"
      },
      "source": [
        "# \"TFX: ejemplo con un dataset de Stack Overflow con InteractiveContext\"\n",
        "> Ejemplo sencillo de TFX con un dataset de posts de Stack Overflow con InteractiveContext.\n",
        "\n",
        "\n",
        "- toc: true \n",
        "- badges: true \n",
        "- comments: true\n",
        "- categories: [\"Natural language processing\", \"Google Cloud\"]\n",
        "- image: images/googlecloud.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAD1tLoTm_QS"
      },
      "source": [
        "## 1. Introducción\n",
        "\n",
        "Este notebook implementa una ejecución interactiva de los componentes individuales de un pipeline de TensorFlow Extended (TFX). TFX es una plataforma extremo a extremo para el despliegue de modelos de ML en producción. En TFX se define un DAG con una serie de componentes, muchos de las cuales están definidas por el propio TFX. Los componentes implementados son los principales usados desde la ingestión a la puesta del modelo en servicio en producción. Se usa Keras y TensorFlow 2.\n",
        "\n",
        "Se pueden usar los componentes estándar de TFX y sus dependencias entre ellos (es decir, qué componente es continuación de otro), ó bien que el desarrollador defina las dependencias con `add_downstream_node / add_upstream_node`(disponible en cada componente, pej en el componente [Trainer](https://www.tensorflow.org/tfx/api_docs/python/tfx/components/Trainer#add_downstream_node)). Nótese que **algunas dependencias son implícitas**, pej: el componente [Pusher](https://www.tensorflow.org/tfx/guide/pusher) va siempre después de [Trainer](https://www.tensorflow.org/tfx/guide/trainer).\n",
        "\n",
        "Se puede leer la historia de TFX [aqui](https://blog.tensorflow.org/2020/09/brief-history-of-tensorflow-extended-tfx.html).\n",
        "\n",
        "TFX implementa componentes estándar y las librerías Python para usarlas, las cuales están ya implementadas y listas para usar. \n",
        "\n",
        "**Ejecución:** TFX permite la ejecución en orquestradores como Apache Airflow, Kubeflow Pipelines ó Apache Beam. En este notebook el orquestrador será el propio Notebook ya que se va a usar un entorno interactivo.\n",
        "\n",
        "**Metadatos:** en un entorno en producción, los metadatos se almacenan con el ML Metadata (MLMD) API. MLMD almacena las propiedades de los metadatos en una base de datos comom MySQL ó SQLite, y el contenido en almacenamiento persistente como un disco duro. En en notebook interactico, ambas propiedades y contenido de los metadatos se almacenan los almacena en el directorio `/tmp` del notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ePgV0Lj68Q"
      },
      "source": [
        "## 2. Setup\n",
        "\n",
        "Importamos los paquetes necesarios, incluyendo los componentes estándar de TFX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " # OPCIONAL: en caso de usar Colab\n",
        " !pip3 install tfx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " # OPCIONAL: Restart Colab runtime after installing TFX\n",
        " from google.colab import auth as google_auth\n",
        " google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPCIONAL: en caso de usar AI Platform Notebooks\n",
        "#!gcloud auth login"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIqpWK9efviJ"
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "tf.get_logger().propagate = False\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "import tfx\n",
        "from tfx.components import CsvExampleGen\n",
        "from tfx.components import Evaluator\n",
        "from tfx.components import ExampleValidator\n",
        "from tfx.components import Pusher\n",
        "from tfx.components import ResolverNode\n",
        "from tfx.components import SchemaGen\n",
        "from tfx.components import StatisticsGen\n",
        "from tfx.components import Trainer\n",
        "from tfx.components import Transform\n",
        "from tfx.components.base import executor_spec\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.orchestration import pipeline\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.proto import pusher_pb2\n",
        "from tfx.proto import trainer_pb2\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model\n",
        "from tfx.types.standard_artifacts import ModelBlessing\n",
        "from tfx.utils.dsl_utils import external_input\n",
        "\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCZTHRy0N1D6"
      },
      "source": [
        "Comprobamos versiones de TF y TFX:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ4K18_DN2D8"
      },
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up logging.\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ONIE_hdkPS4"
      },
      "source": [
        "Activamos `InteractiveContext`, lo cual nos permite que el notebook sea el orquestrador y ejecutar los componentes TFX en el propio notebook. `InteractiveContext` es una forma más rápida de usar TFX en un notebook, hacer depuración y fue [lanzado en 2019](https://blog.tensorflow.org/2019/11/introducing-tfx-interactive-notebook.html).\n",
        "\n",
        "Es decir, en este notebook, instanciamos los componentes uno a uno con `InteractiveContext.run()` y se ejecutan en el notebook. En un sistema en producción, los componentes se deben definir dentro de la clase `Pipeline` y se ejecutan en el orquestrador (véase [Building a TFX Pipeline Guide](../tfx/guide/build_tfx_pipeline))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rh6K5sUf9dd"
      },
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
        "# notebook.\n",
        "context = InteractiveContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## 3. Carga de datos\n",
        "\n",
        "Descargamos el dataset de posts de Stack Overflow y convertimos a formato `TFRecord` antes de iniciar el pipeline:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import utils\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "def create_tf_example(text, label):\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'text': tf.train.Feature(bytes_list=tf.train.BytesList(value=[text.encode('utf-8')])),\n",
        "        'label':tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
        "        #'Label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[label.encode('utf-8')])),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
        "dataset = utils.get_file(\n",
        "    'stack_overflow_16k.tar.gz',\n",
        "    data_url,\n",
        "    untar=True,\n",
        "    cache_dir='stack_overflow',\n",
        "    cache_subdir='')\n",
        "dataset_dir = pathlib.Path(dataset).parent\n",
        "\n",
        "# Read train data as TFRecords\n",
        "labels_dict = {'java':0, 'python':1, 'csharp':2, 'javascript':3}\n",
        "with tf.io.TFRecordWriter(str(dataset_dir/'train/stackoverflow-train.tfrecords')) as writer:\n",
        "    for train_directory in [dataset_dir/'train/java', dataset_dir/'train/python', dataset_dir/'train/csharp', dataset_dir/'train/javascript']:\n",
        "        print(\"Generating: TRAIN \",train_directory.parts[-1], \" \", len(list(train_directory.glob('*'))))\n",
        "        for file in Path(train_directory).iterdir():\n",
        "            if file.is_file():\n",
        "                with open (file, \"r\") as myfile:\n",
        "                    data = myfile.read().replace(\"\\n\", \" \")\n",
        "                myfile.close()\n",
        "            # data: text; labels: int64, according to labels_dict\n",
        "            example = create_tf_example(data, labels_dict[ str(train_directory.parts[-1]) ])\n",
        "            writer.write(example.SerializeToString())\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## 4. Ejecución interactiva de los componentes TFX individuales\n",
        "En las siguientes celdas, se van a ejecutar los componentes de TFX uno a uno, y se visualizarán algunos artifacts de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fwt9gQk3BR"
      },
      "source": [
        "### ExampleGen\n",
        "\n",
        "El componente `ExampleGen` es normalmente el **primero del pipeline de TFX**. Genera datos para otros componentes como `SchemaGen`, `StatisticsGen`, `Transform` y otros.Permite leer de CSV, tf.record y Bigquery, pero se podría crear un executor para leer de Avro ó parque. Puede hacer un split de train/eval, ó importar el que ya esté hecho.\n",
        "\n",
        "Funciones:\n",
        "\n",
        "1.   Realiza split de datos en entrenamiento y evaluación (por defecto, 2/3 entrenamiento + 1/3 evaluación)\n",
        "2.   Convierte datos en formato `tf.Example` \n",
        "3.   Copia datos en el directorio `_tfx_root` para que accedan otros componentes\n",
        "\n",
        "`ExampleGen` takes as input the path to your data source. In our case, this is the `_data_root` path that contains the downloaded CSV.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from tfx.components.example_gen.import_example_gen.component import ImportExampleGen\n",
        "from tfx.proto import example_gen_pb2\n",
        "\n",
        "\n",
        "path_to_tfrecord_dir = str(dataset_dir/'train')\n",
        "\n",
        "# Output 2 splits: train:eval=3:1.\n",
        "output = example_gen_pb2.Output(\n",
        "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
        "                 example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=3),\n",
        "                 example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
        "             ]))\n",
        "example_gen = ImportExampleGen(input_base=path_to_tfrecord_dir, output_config=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.run(example_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqCoZh7KPUm9"
      },
      "source": [
        "Artifacts de salida de `ExampleGen`. Este componente genera **dos artifacts**, el artifact de entrenamiento y el de evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "880KkTAkPeUg"
      },
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "print(artifact.split_names, artifact.uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6vcbW_wPqvl"
      },
      "source": [
        "Vemos las tres primeras muestras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4XIXjiCPwzQ"
      },
      "source": [
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gluYjccf-IP"
      },
      "source": [
        "Una vez que `ExampleGen` ha terminado la ingestión, pasamos al análisis de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### StatisticsGen\n",
        "El componente `StatisticsGen` calcula estadísticas de tu dataset para su análisis, y para uso de componentes posteriores en el pipeline. Hace uso de la librería [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "`StatisticsGen` tiene como entrada los datos ingestados de `ExampleGen`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAscCCYWgA-9"
      },
      "source": [
        "statistics_gen = StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLjXy7K6Tp_G"
      },
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLI6cb_5WugZ"
      },
      "source": [
        "Artifacts de salida de `StatisticsGen`. Se pueden generar diferentes gráficas distintas a la mostrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p"
      },
      "source": [
        "### SchemaGen\n",
        "\n",
        "El componente `SchemaGen` genera un esquema de tus datos. Un esquema define los tipos de datos, márgenes y propiedades de las features de tu dataset. Usa la librería de [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "El esquema generado es best-effort, ya que simplemente hace lo que puede para averiguar ciertas propiedades de los datos. Se espera que el usuario revise y modifique según aplique.\n",
        "\n",
        "Note: The generated schema is best-effort and only tries to infer basic properties of the data. It is expected that you review and modify it as needed.\n",
        "\n",
        "`SchemaGen` usa como entrada las estadísticas generadas con `StatisticsGen`, mirando al split de datos usado por defecto.\n",
        "\n",
        "IMPORTANTE: the desired behavior of infer_schema(..., infer_feature_shape=True) would be to infer feature shapes for FixedLenFeatures while parsing VarLenFeatures to SparseFeatures in the schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygQvZ6hsiQ_J"
      },
      "source": [
        "schema_gen = SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=True)\n",
        "context.run(schema_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6TxTUKXM6b"
      },
      "source": [
        "Artifact de salida de `SchemaGen`, que es el esquema mostrado como tabla:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec9vqDXpXeMb"
      },
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWWdbA-m7zp"
      },
      "source": [
        "Each feature in your dataset shows up as a row in the schema table, alongside its properties. The schema also captures all the values that a categorical feature takes on, denoted as its domain.\n",
        "\n",
        "To learn more about schemas, see [the SchemaGen documentation](https://www.tensorflow.org/tfx/guide/schemagen)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8"
      },
      "source": [
        "### ExampleValidator\n",
        "El componente `ExampleValidator` detecta anomalías en los datos, según el esquema generado anteriormente. Hace uso de la librería  [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) .\n",
        "\n",
        "`ExampleValidator` usa como entrada la salida de `StatisticsGen`, y la salida de `SchemaGen` (esquema)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRlRUuGgiXks"
      },
      "source": [
        "example_validator = ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855mrHgJcoer"
      },
      "source": [
        "Artifact de salida de `ExampleValidator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDyAAozQcrk3"
      },
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znMoJj60ybZx"
      },
      "source": [
        "In the anomalies table, we can see that there are no anomalies. This is what we'd expect, since this the first dataset that we've analyzed and the schema is tailored to it. You should review this schema -- anything unexpected means an anomaly in the data. Once reviewed, the schema can be used to guard future data, and anomalies produced here can be used to debug model performance, understand how your data evolves over time, and identify data errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36"
      },
      "source": [
        "### Transform\n",
        "El componente `Transform` realiza **Feature engineering** tanto en entrenamiento como en serving. Hace uso de la librería [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started).\n",
        "\n",
        "`Transform` toma como entrada los datos de `ExampleGen`, el esquema de `SchemaGen` (ojo al parámetro `infer_feature_shape`), así como el código python que realiza la transformación.\n",
        "\n",
        "Let's see an example of user-defined Transform code below (for an introduction to the TensorFlow Transform APIs, [see the tutorial](https://www.tensorflow.org/tfx/tutorials/transform/simple)). First, we define a few constants for feature engineering:\n",
        "\n",
        "Nota: La celda `%%writefile` graba el contenido `.py` en un archivo, que luego se carga al llamar al componente `Transform`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuNSiUKb4YJf"
      },
      "source": [
        "_stackoverflow_constants_module_file = 'stackoverflow_constants.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPjhXuIF4YJh"
      },
      "source": [
        "%%writefile {_stackoverflow_constants_module_file}\n",
        "\n",
        "_FEATURE_KEY = 'text'\n",
        "_LABEL_KEY = 'label'\n",
        "\n",
        "_DROPOUT_RATE = 0.2\n",
        "_EMBEDDING_UNITS = 64\n",
        "_EVAL_BATCH_SIZE = 5\n",
        "_HIDDEN_UNITS = 64\n",
        "_LEARNING_RATE = 1e-4\n",
        "_L2_REGULARIZER=0.01\n",
        "_LSTM_UNITS = 64\n",
        "_VOCAB_SIZE = 8000\n",
        "_MAX_LEN = 400\n",
        "_TRAIN_BATCH_SIZE = 10\n",
        "_NUM_CLASSES = 4\n",
        "_NUM_FILTERS=200\n",
        "_FILTER_SIZE=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj2Ax5z4YJl"
      },
      "source": [
        "Escribimos la función `preprocessing_fn` que es la que llamará el componente `Transform`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AJ9hBs94YJm"
      },
      "source": [
        "_stackoverflow_transform_module_file = 'stackoverflow_transform.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYmxxx9A4YJn"
      },
      "source": [
        "%%writefile {_stackoverflow_transform_module_file}\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from typing import List, Text\n",
        "\n",
        "import stackoverflow_constants\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs\n",
        "\n",
        "_FEATURE_KEY = stackoverflow_constants._FEATURE_KEY\n",
        "_LABEL_KEY = stackoverflow_constants._LABEL_KEY\n",
        "\n",
        "_DROPOUT_RATE = stackoverflow_constants._DROPOUT_RATE\n",
        "_EMBEDDING_UNITS = stackoverflow_constants._EMBEDDING_UNITS\n",
        "_EVAL_BATCH_SIZE = stackoverflow_constants._EVAL_BATCH_SIZE\n",
        "_HIDDEN_UNITS = stackoverflow_constants._HIDDEN_UNITS\n",
        "_LEARNING_RATE = stackoverflow_constants._LEARNING_RATE\n",
        "_L2_REGULARIZER = stackoverflow_constants._L2_REGULARIZER\n",
        "_LSTM_UNITS = stackoverflow_constants._LSTM_UNITS\n",
        "_VOCAB_SIZE = stackoverflow_constants._VOCAB_SIZE\n",
        "_MAX_LEN = stackoverflow_constants._MAX_LEN\n",
        "_TRAIN_BATCH_SIZE = stackoverflow_constants._TRAIN_BATCH_SIZE\n",
        "_NUM_CLASSES = stackoverflow_constants._NUM_CLASSES\n",
        "_NUM_FILTERS= stackoverflow_constants._NUM_FILTERS\n",
        "_FILTER_SIZE= stackoverflow_constants._FILTER_SIZE\n",
        "\n",
        "def _transformed_name(key, is_input=False):\n",
        "  return key + ('_xf_input' if is_input else '_xf')\n",
        "\n",
        "def _tokenize_text(text):\n",
        "  print(text)\n",
        "  text_sparse = tf.strings.split(tf.reshape(text, [-1])).to_sparse()\n",
        "  # tft.apply_vocabulary doesn't reserve 0 for oov words. In order to comply\n",
        "  # with convention and use mask_zero in keras.embedding layer, set oov value\n",
        "  # to _VOCAB_SIZE and padding value to -1. Then add 1 to all the tokens.\n",
        "  text_indices = tft.compute_and_apply_vocabulary(\n",
        "      text_sparse, default_value=_VOCAB_SIZE, top_k=_VOCAB_SIZE)\n",
        "  dense = tf.sparse.to_dense(text_indices, default_value=-1)\n",
        "  # TFX transform expects the transform result to be FixedLenFeature.\n",
        "  padding_config = [[0, 0], [0, _MAX_LEN]]\n",
        "  dense = tf.pad(dense, padding_config, 'CONSTANT', -1)\n",
        "  padded = tf.slice(dense, [0, 0], [-1, _MAX_LEN])\n",
        "  padded += 1\n",
        "  return padded\n",
        "\n",
        "\n",
        "# TFX Transform will call this function.\n",
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "  Args:\n",
        "    inputs: map from feature keys to raw not-yet-transformed features.\n",
        "  Returns:\n",
        "    Map from string feature key to transformed feature operations.\n",
        "  \"\"\"\n",
        "  return {\n",
        "      _transformed_name(_LABEL_KEY):\n",
        "          inputs[_LABEL_KEY],\n",
        "      _transformed_name(_FEATURE_KEY, True):\n",
        "          _tokenize_text(inputs[_FEATURE_KEY])\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbmZr3sgbWW"
      },
      "source": [
        "Ejecutamos el componente `Transform` que transforma los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHfhth_GiZI9"
      },
      "source": [
        "transform = Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_stackoverflow_transform_module_file))\n",
        "\n",
        "context.run(transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAwb4rARRQ2"
      },
      "source": [
        "Artifacts de salida de `Transform`. Genera dos artifacts:\n",
        "\n",
        "* `transform_graph` is the graph that can perform the preprocessing operations (this graph will be included in the serving and evaluation models).\n",
        "* `transformed_examples` represents the preprocessed training and evaluation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SClrAaEGR1O5"
      },
      "source": [
        "transform.outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFkBd9AR1sy"
      },
      "source": [
        "Vemos el artifact `transform_graph`, que apunta a un directorio que contiene 3 subdirectorios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tRw4DneR3i7"
      },
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
        "os.listdir(train_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fqV54CIR6Pu"
      },
      "source": [
        "1. El subdirectorio `transformed_metadata` contiene el esquema de los datos preprocesados. \n",
        "2. El subdirectorio `transform_fn` contiene el grfo de procesado. \n",
        "3. El subdirectorio `metadata` contiene el esquema de los datos originales.\n",
        "\n",
        "Vamos las tres primeras transformaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwbW2zPKR_S4",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_b_V6eN4f69"
      },
      "source": [
        "Después de tokenizar con el componente `Transform`, el siguiente paso es el entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9"
      },
      "source": [
        "### Trainer\n",
        "El componente `Trainer` entrena un modelo definido en TensorFlow. Default Trainer support Estimator API, to use Keras API, you need to specify [Generic Trainer](https://github.com/tensorflow/community/blob/master/rfcs/20200117-tfx-generic-trainer.md) by setup `custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor)` in Trainer's contructor.\n",
        "\n",
        "`Trainer` toma como entrada el esquema de `SchemaGen`, los datos transformados y el grafo de `Transform`, parámetros de entrenamiento, y el código python para entrenar.\n",
        "\n",
        "Let's see an example of user-defined model code below (for an introduction to the TensorFlow Keras APIs, [see the tutorial](https://www.tensorflow.org/guide/keras)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1376oq04YJt"
      },
      "source": [
        "_stackoverflow_trainer_module_file = 'stackoverflow_trainer.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf9UuNng4YJu"
      },
      "source": [
        "%%writefile {_stackoverflow_trainer_module_file}\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from typing import List, Text\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs\n",
        "\n",
        "import stackoverflow_constants\n",
        "\n",
        "_FEATURE_KEY = stackoverflow_constants._FEATURE_KEY\n",
        "_LABEL_KEY = stackoverflow_constants._LABEL_KEY\n",
        "\n",
        "_DROPOUT_RATE = stackoverflow_constants._DROPOUT_RATE\n",
        "_EMBEDDING_UNITS = stackoverflow_constants._EMBEDDING_UNITS\n",
        "_EVAL_BATCH_SIZE = stackoverflow_constants._EVAL_BATCH_SIZE\n",
        "_HIDDEN_UNITS = stackoverflow_constants._HIDDEN_UNITS\n",
        "_LEARNING_RATE = stackoverflow_constants._LEARNING_RATE\n",
        "_L2_REGULARIZER = stackoverflow_constants._L2_REGULARIZER\n",
        "_LSTM_UNITS = stackoverflow_constants._LSTM_UNITS\n",
        "_VOCAB_SIZE = stackoverflow_constants._VOCAB_SIZE\n",
        "_MAX_LEN = stackoverflow_constants._MAX_LEN\n",
        "_TRAIN_BATCH_SIZE = stackoverflow_constants._TRAIN_BATCH_SIZE\n",
        "_NUM_CLASSES = stackoverflow_constants._NUM_CLASSES\n",
        "_NUM_FILTERS= stackoverflow_constants._NUM_FILTERS\n",
        "_FILTER_SIZE= stackoverflow_constants._FILTER_SIZE\n",
        "\n",
        "def _transformed_name(key, is_input=False):\n",
        "  return key + ('_xf_input' if is_input else '_xf')\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "  return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "\n",
        "def _input_fn(file_pattern: List[Text],\n",
        "              tf_transform_output: tft.TFTransformOutput,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "\n",
        "  transformed_feature_spec = (\n",
        "      tf_transform_output.transformed_feature_spec().copy())\n",
        "\n",
        "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "      file_pattern=file_pattern,\n",
        "      batch_size=batch_size,\n",
        "      features=transformed_feature_spec,\n",
        "      reader=_gzip_reader_fn,\n",
        "      label_key=_transformed_name(_LABEL_KEY))\n",
        "\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def _build_keras_model() -> keras.Model:\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Embedding(_VOCAB_SIZE + 2,_EMBEDDING_UNITS,name=_transformed_name(_FEATURE_KEY)),\n",
        "      #keras.layers.Bidirectional(keras.layers.LSTM(_LSTM_UNITS, dropout=_DROPOUT_RATE)),\n",
        "      keras.layers.Reshape((_MAX_LEN, _EMBEDDING_UNITS, 1)),\n",
        "      keras.layers.Conv2D(_NUM_FILTERS,(_FILTER_SIZE,_EMBEDDING_UNITS),activation='relu',kernel_regularizer=keras.regularizers.l2(_L2_REGULARIZER)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dropout(_DROPOUT_RATE),\n",
        "      keras.layers.Dense(_HIDDEN_UNITS, activation='relu'),\n",
        "      keras.layers.Dense(_NUM_CLASSES, activation ='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      optimizer=keras.optimizers.Adam(_LEARNING_RATE),\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "  model.summary(print_fn=absl.logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "\n",
        "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "  @tf.function\n",
        "  def serve_tf_examples_fn(serialized_tf_examples):\n",
        "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "    feature_spec = tf_transform_output.raw_feature_spec()\n",
        "    feature_spec.pop(_LABEL_KEY)\n",
        "    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "    transformed_features = model.tft_layer(parsed_features)\n",
        "    return model(transformed_features)\n",
        "\n",
        "  return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: FnArgs):\n",
        "\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files, tf_transform_output, batch_size=_TRAIN_BATCH_SIZE)\n",
        "\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files, tf_transform_output, batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "  with mirrored_strategy.scope():\n",
        "    model = _build_keras_model()\n",
        "\n",
        "\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "  signatures = {\n",
        "      'serving_default':\n",
        "          _get_serve_tf_examples_fn(model,\n",
        "                                    tf_transform_output).get_concrete_function(\n",
        "                                        tf.TensorSpec(\n",
        "                                            shape=[None],\n",
        "                                            dtype=tf.string,\n",
        "                                            name='examples')),\n",
        "  }\n",
        "\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY4yTRaX4YJx"
      },
      "source": [
        "Pasamos el código al componente `Trainer` para entrenar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "429-vvCWibO0"
      },
      "source": [
        "trainer = Trainer(\n",
        "    module_file=os.path.abspath(_stackoverflow_trainer_module_file),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=3000),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=3000))\n",
        "context.run(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cql1G35StJp"
      },
      "source": [
        "#### Analyze Training with TensorBoard\n",
        "Take a peek at the trainer artifact. It points to a directory containing the model subdirectories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXe62WE0S0Ek"
      },
      "source": [
        "model_artifact_dir = trainer.outputs['model'].get()[0].uri\n",
        "pp.pprint(os.listdir(model_artifact_dir))\n",
        "model_dir = os.path.join(model_artifact_dir, 'serving_model_dir')\n",
        "pp.pprint(os.listdir(model_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfjOmSro6Q3Y"
      },
      "source": [
        "Optionally, we can connect TensorBoard to the Trainer to analyze our model's training curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-APzqz2NeAyj"
      },
      "source": [
        "#model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir {model_run_artifact_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmPftrv0lEQy"
      },
      "source": [
        "### Evaluator\n",
        "El componente `Evaluator` evalúa métricas sobre el set de evaluación. hace uso de la librería [TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started). `Evaluator` también valida si un modelo nuevo es mejor que el anterior, y en caso afirmativo, lo promociona. Esto es útil en el case de un pipeline de producción donde se entrenan y validan modelos diariamente. en este notebook sólo entrenamos un modelo, así que es el único que se promociona en cualqui caso.\n",
        "\n",
        "`Evaluator` tomo como entrada `ExampleGen`, el modelo de `Trainer`, and slicing configuration. The slicing configuration allows you to slice your metrics on feature values (e.g. how does your model perform on taxi trips that start at 8am versus 8pm?). See an example of this configuration below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(example_gen.outputs['examples'])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVhfzzh9PDEx"
      },
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "      model_specs=[tfma.ModelSpec(label_key='label')],\n",
        "      slicing_specs=[tfma.SlicingSpec()],\n",
        "      metrics_specs=[\n",
        "          tfma.MetricsSpec(metrics=[\n",
        "              tfma.MetricConfig(\n",
        "                  class_name='SparseCategoricalAccuracy',\n",
        "                  threshold=tfma.MetricThreshold(\n",
        "                      value_threshold=tfma.GenericValueThreshold(\n",
        "                          # Si el modelo no tiene una precisión mayor de 0.8\n",
        "                          lower_bound={'value': 0.8}),\n",
        "                      change_threshold=tfma.GenericChangeThreshold(\n",
        "                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                          absolute={'value': -1e-2})))\n",
        "          ])\n",
        "      ]\n",
        "      )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mBdKH1F8JuT"
      },
      "source": [
        "Pasamos la configuración anterior al componente `Evaluator`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjcx8g6mihSt"
      },
      "source": [
        "from tfx.types import standard_artifacts\n",
        "from tfx.types import channel\n",
        "\n",
        "# Use TFMA to compute a evaluation statistics over features of a model and\n",
        "# validate them against a baseline.\n",
        "\n",
        "# The model resolver is only required if performing model validation in addition\n",
        "# to evaluation. In this case we validate against the latest blessed model. If\n",
        "# no model has been blessed before (as in this case) the evaluator will make our\n",
        "# candidate the first blessed model.\n",
        "model_resolver = ResolverNode(\n",
        "      instance_name='latest_blessed_model_resolver',\n",
        "      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
        "      model=Channel(type=Model),\n",
        "      model_blessing=Channel(type=ModelBlessing))\n",
        "context.run(model_resolver)\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    # Change threshold will be ignored if there is no baseline (first run).\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCVkBusS_8g"
      },
      "source": [
        "Now let's examine the output artifacts of `Evaluator`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4GghePOTJxL"
      },
      "source": [
        "evaluator.outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TMskWe9LL0"
      },
      "source": [
        "Using the `evaluation` output we can show the default visualization of global metrics on the entire evaluation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U729j5X5QQUQ"
      },
      "source": [
        "context.show(evaluator.outputs['evaluation'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tI4p6m-OAn"
      },
      "source": [
        "To see the visualization for sliced evaluation metrics, we can directly call the TensorFlow Model Analysis library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyis6iy0HLdi"
      },
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "#tfma.view.render_slicing_metrics(\n",
        "#    tfma_result, slicing_column='trip_start_hour')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvYrUf2-r_6"
      },
      "source": [
        "This visualization shows the same metrics, but computed at every feature value of `trip_start_hour` instead of on the entire evaluation set.\n",
        "\n",
        "TensorFlow Model Analysis supports many other visualizations, such as Fairness Indicators and plotting a time series of model performance. To learn more, see [the tutorial](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEotnkxEswUb"
      },
      "source": [
        "Al añadir umbrales a la configuración, podemos ver también la salida de la validación. La presencia de un artifact `blessing` (bendecido) indica que nuestro modelo pasó la validación. Si esta es la primera validación, el modelo candidato es automáticamente bendecido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZmiRtg6TKtR"
      },
      "source": [
        "blessing_uri = evaluator.outputs.blessing.get()[0].uri\n",
        "!ls -l {blessing_uri}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1tFkOVSBa0"
      },
      "source": [
        "Now can also verify the success by loading the validation result record:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxa5G08bSJ8a"
      },
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8DYekCZlHfj"
      },
      "source": [
        "### Pusher\n",
        "El componente `Pusher` suele ser el último del pipeline de TFX. Comprueba si se ha pasado la validación, y exporta el modelo al directorio `_serving_model_dir`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r45nQ69eikc9"
      },
      "source": [
        "_serving_model_dir = os.path.join(\"./\", \"my_serving_model\")\n",
        "\n",
        "\n",
        "pusher = Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=pusher_pb2.PushDestination(\n",
        "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "context.run(pusher)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctUErBYoTO9I"
      },
      "source": [
        "Artifacts de salida de `Pusher`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRkWo-MzTSss"
      },
      "source": [
        "pusher.outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peH2PPS3VgkL"
      },
      "source": [
        "En concreto, `Pusher` puede exportar el modelo en formato SavedModel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zyIqWl9TSdG"
      },
      "source": [
        "push_uri = pusher.outputs.model_push.get()[0].uri\n",
        "model = tf.saved_model.load(push_uri)\n",
        "\n",
        "for item in model.signatures.items():\n",
        "  pp.pprint(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-YPNUuHANtj"
      },
      "source": [
        "Esto concluye el pipeline de TFX"
      ]
    }
  ]
}