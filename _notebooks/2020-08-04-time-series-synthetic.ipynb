{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S+P Week 4 Lesson 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \"Series temporales: datos sintéticos\"\n",
        "> (SPANISH) Generación de datos sintéticos para series temporales \n",
        "\n",
        "\n",
        "- toc: true \n",
        "- badges: true \n",
        "- comments: true\n",
        "- categories: [tensorflow]\n",
        "- image: images/kaggle.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "D1J15Vh_1Jih",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOjujz601HcS",
        "colab": {},
        "tags": []
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.2.0-dev20200507\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zswl7jRtGzkk",
        "colab": {}
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope=0):\n",
        "    return slope * time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level\n",
        "\n",
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "baseline = 10\n",
        "series = trend(time, 0.1)  \n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.05\n",
        "noise_level = 5\n",
        "\n",
        "# Create the series\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "# Update with noise\n",
        "series += noise(time, noise_level, seed=42)\n",
        "\n",
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4sTTIOCbyShY",
        "colab": {}
      },
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eaAX9g_jS5W",
        "colab": {}
      },
      "source": [
        "def model_forecast(model, series, window_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.batch(32).prefetch(1)\n",
        "    forecast = model.predict(ds)\n",
        "    return forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yqc2GTsps0qf",
        "colab": {},
        "tags": []
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "window_size = 30\n",
        "train_set = windowed_dataset(x_train, window_size, batch_size=128, shuffle_buffer=shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 200)\n",
        "])\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/100\n8/8 [==============================] - 1s 64ms/step - loss: 73.1912 - mae: 73.6903\nEpoch 2/100\n8/8 [==============================] - 0s 49ms/step - loss: 72.4799 - mae: 72.9791\nEpoch 3/100\n8/8 [==============================] - 0s 46ms/step - loss: 71.3446 - mae: 71.8437\nEpoch 4/100\n8/8 [==============================] - 0s 37ms/step - loss: 69.9230 - mae: 70.4223\nEpoch 5/100\n8/8 [==============================] - 0s 54ms/step - loss: 68.2678 - mae: 68.7669\nEpoch 6/100\n8/8 [==============================] - 0s 40ms/step - loss: 66.3621 - mae: 66.8609\nEpoch 7/100\n8/8 [==============================] - 0s 48ms/step - loss: 64.2432 - mae: 64.7424\nEpoch 8/100\n8/8 [==============================] - 0s 43ms/step - loss: 61.8749 - mae: 62.3738\nEpoch 9/100\n8/8 [==============================] - 1s 64ms/step - loss: 59.2491 - mae: 59.7479\nEpoch 10/100\n8/8 [==============================] - 0s 48ms/step - loss: 56.3267 - mae: 56.8254\nEpoch 11/100\n8/8 [==============================] - 0s 54ms/step - loss: 53.0701 - mae: 53.5686\nEpoch 12/100\n8/8 [==============================] - 0s 47ms/step - loss: 49.3867 - mae: 49.8850\nEpoch 13/100\n8/8 [==============================] - 0s 46ms/step - loss: 45.1183 - mae: 45.6166\nEpoch 14/100\n8/8 [==============================] - 0s 39ms/step - loss: 41.6539 - mae: 42.1518\nEpoch 15/100\n8/8 [==============================] - 0s 43ms/step - loss: 40.6341 - mae: 41.1322\nEpoch 16/100\n8/8 [==============================] - 0s 49ms/step - loss: 39.5119 - mae: 40.0100\nEpoch 17/100\n8/8 [==============================] - 0s 40ms/step - loss: 38.1009 - mae: 38.5986\nEpoch 18/100\n8/8 [==============================] - 0s 49ms/step - loss: 36.5304 - mae: 37.0279\nEpoch 19/100\n8/8 [==============================] - 0s 39ms/step - loss: 34.9672 - mae: 35.4642\nEpoch 20/100\n8/8 [==============================] - 0s 47ms/step - loss: 33.5379 - mae: 34.0347\nEpoch 21/100\n8/8 [==============================] - 0s 50ms/step - loss: 32.2358 - mae: 32.7321\nEpoch 22/100\n8/8 [==============================] - 0s 46ms/step - loss: 31.0509 - mae: 31.5469\nEpoch 23/100\n8/8 [==============================] - 0s 41ms/step - loss: 29.9243 - mae: 30.4202\nEpoch 24/100\n8/8 [==============================] - 0s 51ms/step - loss: 28.8317 - mae: 29.3274\nEpoch 25/100\n8/8 [==============================] - 0s 52ms/step - loss: 27.7314 - mae: 28.2272\nEpoch 26/100\n8/8 [==============================] - 0s 44ms/step - loss: 26.6107 - mae: 27.1066\nEpoch 27/100\n8/8 [==============================] - 0s 38ms/step - loss: 25.4565 - mae: 25.9519\nEpoch 28/100\n8/8 [==============================] - 0s 62ms/step - loss: 24.2668 - mae: 24.7617\nEpoch 29/100\n8/8 [==============================] - 0s 38ms/step - loss: 23.0459 - mae: 23.5406\nEpoch 30/100\n8/8 [==============================] - 0s 45ms/step - loss: 21.8057 - mae: 22.3000\nEpoch 31/100\n8/8 [==============================] - 0s 40ms/step - loss: 20.5264 - mae: 21.0202\nEpoch 32/100\n8/8 [==============================] - 0s 61ms/step - loss: 19.2341 - mae: 19.7269\nEpoch 33/100\n8/8 [==============================] - 0s 52ms/step - loss: 17.9646 - mae: 18.4568\nEpoch 34/100\n8/8 [==============================] - 0s 41ms/step - loss: 16.9362 - mae: 17.4279\nEpoch 35/100\n8/8 [==============================] - 0s 42ms/step - loss: 16.2657 - mae: 16.7576\nEpoch 36/100\n8/8 [==============================] - 0s 40ms/step - loss: 15.6281 - mae: 16.1192\nEpoch 37/100\n8/8 [==============================] - 0s 38ms/step - loss: 15.0540 - mae: 15.5447\nEpoch 38/100\n8/8 [==============================] - 0s 49ms/step - loss: 14.5219 - mae: 15.0126\nEpoch 39/100\n8/8 [==============================] - 0s 41ms/step - loss: 13.9836 - mae: 14.4747\nEpoch 40/100\n8/8 [==============================] - 0s 53ms/step - loss: 13.4414 - mae: 13.9318\nEpoch 41/100\n8/8 [==============================] - 0s 43ms/step - loss: 12.8781 - mae: 13.3677\nEpoch 42/100\n8/8 [==============================] - 0s 50ms/step - loss: 12.2855 - mae: 12.7749\nEpoch 43/100\n8/8 [==============================] - 0s 45ms/step - loss: 11.6690 - mae: 12.1582\nEpoch 44/100\n8/8 [==============================] - 0s 38ms/step - loss: 11.0181 - mae: 11.5063\nEpoch 45/100\n8/8 [==============================] - 0s 41ms/step - loss: 10.3387 - mae: 10.8260\nEpoch 46/100\n8/8 [==============================] - 0s 42ms/step - loss: 9.6894 - mae: 10.1757\nEpoch 47/100\n8/8 [==============================] - 0s 38ms/step - loss: 9.0956 - mae: 9.5809\nEpoch 48/100\n8/8 [==============================] - 0s 59ms/step - loss: 8.5688 - mae: 9.0536\nEpoch 49/100\n8/8 [==============================] - 0s 49ms/step - loss: 8.1153 - mae: 8.5996\nEpoch 50/100\n8/8 [==============================] - 0s 40ms/step - loss: 7.7040 - mae: 8.1884\nEpoch 51/100\n8/8 [==============================] - 0s 39ms/step - loss: 7.3262 - mae: 7.8096\nEpoch 52/100\n8/8 [==============================] - 0s 46ms/step - loss: 6.9725 - mae: 7.4548\nEpoch 53/100\n8/8 [==============================] - 0s 52ms/step - loss: 6.6218 - mae: 7.1033\nEpoch 54/100\n8/8 [==============================] - 0s 41ms/step - loss: 6.2898 - mae: 6.7712\nEpoch 55/100\n8/8 [==============================] - 0s 43ms/step - loss: 5.9775 - mae: 6.4581\nEpoch 56/100\n8/8 [==============================] - 0s 44ms/step - loss: 5.7096 - mae: 6.1898\nEpoch 57/100\n8/8 [==============================] - 0s 41ms/step - loss: 5.4204 - mae: 5.8992\nEpoch 58/100\n8/8 [==============================] - 0s 53ms/step - loss: 5.2126 - mae: 5.6904\nEpoch 59/100\n8/8 [==============================] - 0s 62ms/step - loss: 4.9788 - mae: 5.4558\nEpoch 60/100\n8/8 [==============================] - 0s 38ms/step - loss: 4.8674 - mae: 5.3438\nEpoch 61/100\n8/8 [==============================] - 0s 40ms/step - loss: 4.7943 - mae: 5.2711\nEpoch 62/100\n8/8 [==============================] - 0s 38ms/step - loss: 4.6056 - mae: 5.0814\nEpoch 63/100\n8/8 [==============================] - 0s 55ms/step - loss: 4.7894 - mae: 5.2667\nEpoch 64/100\n8/8 [==============================] - 0s 51ms/step - loss: 5.3933 - mae: 5.8745\nEpoch 65/100\n8/8 [==============================] - 0s 39ms/step - loss: 5.8707 - mae: 6.3541\nEpoch 66/100\n8/8 [==============================] - 0s 41ms/step - loss: 5.9398 - mae: 6.4232\nEpoch 67/100\n8/8 [==============================] - 0s 61ms/step - loss: 4.9885 - mae: 5.4691\nEpoch 68/100\n8/8 [==============================] - 0s 47ms/step - loss: 4.9485 - mae: 5.4277\nEpoch 69/100\n8/8 [==============================] - 0s 44ms/step - loss: 5.5203 - mae: 6.0028\nEpoch 70/100\n8/8 [==============================] - 0s 38ms/step - loss: 6.2567 - mae: 6.7418\nEpoch 71/100\n8/8 [==============================] - 0s 47ms/step - loss: 5.9135 - mae: 6.3976\nEpoch 72/100\n8/8 [==============================] - 0s 47ms/step - loss: 6.7331 - mae: 7.2217\nEpoch 73/100\n8/8 [==============================] - 0s 43ms/step - loss: 6.8394 - mae: 7.3263\nEpoch 74/100\n8/8 [==============================] - 0s 49ms/step - loss: 7.1395 - mae: 7.6270\nEpoch 75/100\n8/8 [==============================] - 0s 40ms/step - loss: 8.3340 - mae: 8.8248\nEpoch 76/100\n8/8 [==============================] - 0s 42ms/step - loss: 9.7772 - mae: 10.2679\nEpoch 77/100\n8/8 [==============================] - 0s 38ms/step - loss: 8.8560 - mae: 9.3441\nEpoch 78/100\n8/8 [==============================] - 0s 46ms/step - loss: 9.5717 - mae: 10.0601\nEpoch 79/100\n8/8 [==============================] - 0s 42ms/step - loss: 17.9317 - mae: 18.4237\nEpoch 80/100\n8/8 [==============================] - 0s 46ms/step - loss: 35.1177 - mae: 35.6156\nEpoch 81/100\n8/8 [==============================] - 0s 46ms/step - loss: 17.8087 - mae: 18.3036\nEpoch 82/100\n8/8 [==============================] - 0s 46ms/step - loss: 16.2955 - mae: 16.7919\nEpoch 83/100\n8/8 [==============================] - 0s 47ms/step - loss: 15.0972 - mae: 15.5927\nEpoch 84/100\n8/8 [==============================] - 0s 47ms/step - loss: 9.0429 - mae: 9.5317\nEpoch 85/100\n8/8 [==============================] - 0s 41ms/step - loss: 8.3368 - mae: 8.8268\nEpoch 86/100\n8/8 [==============================] - 0s 49ms/step - loss: 9.3932 - mae: 9.8812\nEpoch 87/100\n8/8 [==============================] - 0s 53ms/step - loss: 16.2914 - mae: 16.7856\nEpoch 88/100\n8/8 [==============================] - 0s 51ms/step - loss: 15.9402 - mae: 16.4350\nEpoch 89/100\n8/8 [==============================] - 0s 60ms/step - loss: 22.0256 - mae: 22.5212\nEpoch 90/100\n8/8 [==============================] - 0s 57ms/step - loss: 19.5584 - mae: 20.0547\nEpoch 91/100\n8/8 [==============================] - 0s 44ms/step - loss: 20.1753 - mae: 20.6719\nEpoch 92/100\n8/8 [==============================] - 0s 40ms/step - loss: 14.1138 - mae: 14.6060\nEpoch 93/100\n8/8 [==============================] - 0s 51ms/step - loss: 23.2701 - mae: 23.7673\nEpoch 94/100\n8/8 [==============================] - 0s 46ms/step - loss: 17.4064 - mae: 17.9010\nEpoch 95/100\n8/8 [==============================] - 0s 50ms/step - loss: 12.7717 - mae: 13.2629\nEpoch 96/100\n8/8 [==============================] - 0s 62ms/step - loss: 15.7108 - mae: 16.2057\nEpoch 97/100\n8/8 [==============================] - 0s 52ms/step - loss: 17.7694 - mae: 18.2629\nEpoch 98/100\n8/8 [==============================] - 0s 46ms/step - loss: 21.1374 - mae: 21.6334\nEpoch 99/100\n8/8 [==============================] - 0s 41ms/step - loss: 19.1119 - mae: 19.6072\nEpoch 100/100\n8/8 [==============================] - 0s 53ms/step - loss: 19.4526 - mae: 19.9481\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjTvASUns0qh",
        "colab": {}
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4uh-97bpLZCA",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "#batch_size = 16\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=32, kernel_size=3,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "  tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 200)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(dataset,epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MKkic-mLdkRZ",
        "colab": {}
      },
      "source": [
        "rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n",
        "rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4N1toSetdnQq",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, rnn_forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ULKO3JINdqkp",
        "colab": {}
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ok8LjNbbkig4",
        "colab": {}
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "epochs=range(len(loss)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, mae, 'r')\n",
        "plt.plot(epochs, loss, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "epochs_zoom = epochs[200:]\n",
        "mae_zoom = mae[200:]\n",
        "loss_zoom = loss[200:]\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot Zoomed MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs_zoom, mae_zoom, 'r')\n",
        "plt.plot(epochs_zoom, loss_zoom, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}