{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar-10 and kNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "name": "python38564bitfaf5af54669b405a82e8d67cc758ad2e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m26YhtBMvVWA"
      },
      "source": [
        "# \"Clasificador kNN para CIFAR-10\"\n",
        "> Clasificador k-Nearest Neighbor para CIFAR-10, usando la nueva clase experimental tf.numpy. Laboratorio 1 del curso CS231n de Stanford.\n",
        "\n",
        "\n",
        "- toc: true \n",
        "- badges: true \n",
        "- comments: true\n",
        "- categories: [\"Computer Vision\"]\n",
        "- image: images/stanford.png\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b--5FDDwCG9C"
      },
      "source": [
        "## 1. Introducción\n",
        "\n",
        "Este ejemplo muestra cómo hacer una clasificación de imágenes usando Machine Learning clásico, sin usar una red convolucional. \n",
        "Se va a usar k-Nearest Neighbor y una precisión básica basada en diferencia de pixels. \n",
        "Instrucciones originales del [curso de Stanford CS231](https://cs231n.github.io/classification/).  \n",
        "Este ejemplo se ha probado y funciona en Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rstRPH9SyZj_"
      },
      "source": [
        "## 2. Setup\n",
        "Importamos las librerías que vamos a usar. usaremos la función experimental `tensorflow.numpy` para aprovechar las GPUs durante operaciones con funciones `numpy` (por ejemplo, durante la inferencia):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install --quiet --upgrade tf-nightly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as np\n",
        "import numpy\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "source": [
        "Comprobamos si tenemos GPUs. En caso contrario, no notaremos diferencia de velocidad:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"All logical devices:\", tf.config.list_logical_devices())\n",
        "print(\"All physical devices:\", tf.config.list_physical_devices())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BR0POq2UzE7e"
      },
      "source": [
        "## 3. Carga de datos\n",
        "Cargamos el dataset desde `tensorflow.keras.datasets`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43aXKjDRt_qZ",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Usando scikit-learn, Hacemos shuffle y usamos sólo 2000 imágenes para entrenar y 100 para test\n",
        "train_images, train_labels = shuffle(train_images, train_labels)\n",
        "test_images, test_labels = shuffle(test_images, test_labels)\n",
        "\n",
        "train_images = train_images[:2000]\n",
        "train_labels = train_labels[:2000]\n",
        "test_images = test_images[:100]\n",
        "test_labels = test_labels[:100]\n",
        "\n",
        "# Normalizamos valores de píxeles entre 0 y 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eVFsPPEociwF"
      },
      "source": [
        "Visualizamos los primeros 25 elementos del dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-kCqysAuaJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    # The CIFAR labels happen to be arrays, \n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s3F2xbEJdDvN"
      },
      "source": [
        "## 4. Preparar datos\n",
        "El set de entrenamiento original era de tamaño `train_images.shape=(50000,32,32,3)` y sus etiquetas `train_labels.shape=(50000, 1)`. Pero usamos uno más pequeño de 2000. Aplanamos el set de entrenamiento y también el de pruebas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images_rows = train_images.reshape(train_images.shape[0], 32 * 32 * 3) # train_images_rows.shape 2000 x 3072\n",
        "test_images_rows = test_images.reshape(test_images.shape[0], 32 * 32 * 3) # test_images_rows.shape 100 x 3072"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uX4aJYUiXh5",
        "colab_type": "text"
      },
      "source": [
        "## 5. Construcción del modelo\n",
        "Para la predicción, se compara una imagen de test con todas las de entrenamiento, y se devuelve la de menor diferencia (distancia L1: resta de valores de pixels)"
      ]
    },
    {
      "source": [
        "class NearestNeighbor(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, X, y):\n",
        "    \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n",
        "    # the nearest neighbor classifier simply remembers all the training data\n",
        "    self.Xtr = X\n",
        "    self.ytr = y\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\"\n",
        "    num_test = X.shape[0]\n",
        "    # lets make sure that the output type matches the input type\n",
        "    Ypred = []\n",
        "\n",
        "    # loop over all test rows\n",
        "    for i in range(num_test):\n",
        "      # find the nearest training image to the i'th test image\n",
        "      # using the L1 distance (sum of absolute value differences)\n",
        "      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
        "      min_index = np.argmin(distances) # get the index with smallest distance\n",
        "      Ypred.append(self.ytr[min_index]) # predict the label of the nearest example\n",
        "      print(\"Test image {} of {} is {}\".format(i, num_test, Ypred[-1]))\n",
        "\n",
        "\n",
        "    return Ypred"
      ],
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6R4h5HF1Dtds",
        "colab": {}
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Para la predicción, se puede usar la distancia L1 ó L2 (cuadrática). Para la diferencia cuadrática, simplemente cambiar la lína anterior por la siguiente:"
      ],
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3c0o15gVREAw"
      }
    },
    {
      "source": [
        "`distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))`\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "UIWlq3NTYhOl",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ODt86YuVDZzm"
      },
      "source": [
        "## 6. Entrenamiento y evaluación\n",
        "Lanzamos el entrenamiento  usando k Nearest Neighbors (kNN). Para la predicción, se calcula la menor diferencia entre la imagen del set de prueba y todas las imágenes de entrenamiento. Se devuelve la etiqueta de la de menor diferencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_JErW3cw-0J",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "nn = NearestNeighbor() # create a Nearest Neighbor classifier class\n",
        "nn.train(train_images_rows, train_labels) # train the classifier on the training images and labels\n",
        "Yte_predict = nn.predict(test_images_rows) # predict labels on the test images\n",
        "# and now print the classification accuracy, which is the average number\n",
        "# of examples that are correctly predicted (i.e. label matches)\n",
        "print('accuracy: %f' % ( np.mean(np.array(Yte_predict) == test_labels) ))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}