{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkSGVSxZDrx8",
        "colab_type": "text"
      },
      "source": [
        "# \"SPANISH: Introducción a las redes convolucionales\"\n",
        "> (SPANISH) Clasificador binario entre perros y gatos\n",
        "\n",
        "\n",
        "- toc: true \n",
        "- badges: true \n",
        "- comments: true\n",
        "- categories: [tensorflow]\n",
        "- image: images/kaggle.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0B8TOWwCsbM",
        "colab_type": "text"
      },
      "source": [
        "# Redes convolucionales: Cats and Dogs\n",
        "Se entrenará una CNN que distingue entre imágenes de perros y gatos (clasificación binaria)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob2E2ZIeSbDv",
        "colab_type": "text"
      },
      "source": [
        " ## Descargar dataset\n",
        "\n",
        "La descarga no se hace sobre WiFi, sino sobre Colab, con lo que debería ser rápida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aPzoJnd_8QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7EocqtTHnnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# El dataset está en Internet\n",
        "origin = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=origin, extract=True)\n",
        "path_to_folder = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlL8BiAkLn1E",
        "colab_type": "text"
      },
      "source": [
        "Contenido del zip descomprimido:\n",
        "\n",
        "<pre>\n",
        "<b>cats_and_dogs_filtered</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrgB9RwpShf8",
        "colab_type": "text"
      },
      "source": [
        "El dataset está dividido en train y validation. Creamos variables que apunten a esos directorios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4b5Fsw2Lj-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(path_to_folder, 'train')\n",
        "validation_dir = os.path.join(path_to_folder, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG7DjqVkLlCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj1dSkUlLs-m",
        "colab_type": "text"
      },
      "source": [
        "Contamos el número de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfwja3aILv3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('Total training cat images:', num_cats_tr)\n",
        "print('Total training dog images:', num_dogs_tr)\n",
        "print('Total validation cat images:', num_cats_val)\n",
        "print('Total validation dog images:', num_dogs_val)\n",
        "print('---')\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbqGygJHvWd_",
        "colab_type": "text"
      },
      "source": [
        "Hay 3000 imágenes (2000 para entrenar y 1000 para validar). Y está balanceado (mismo número de imágenes de perros y gatos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6HxxIkqSsj6",
        "colab_type": "text"
      },
      "source": [
        "Nota: se pueden ejecutar comandos shell en colab (ejemplo, ```!ls $train_cats_dir```)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bOJXrOqSuoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls $train_cats_dir "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e_9iotCAH8E",
        "colab_type": "text"
      },
      "source": [
        "Mostramos algunas imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAjuM662viPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGVX4U4RTeF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = plt.imshow(plt.imread(os.path.join(train_cats_dir, \"cat.0.jpg\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PM8Th5UAUOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = plt.imshow(plt.imread(os.path.join(train_cats_dir, \"cat.1.jpg\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYj7KnYUvj5v",
        "colab_type": "text"
      },
      "source": [
        "Las imágenes tienen distinto tamaño. Hay que igualarlo antes de introducirlas en la red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1A2CLadVnQa",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesado de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5JfskKZL716",
        "colab_type": "text"
      },
      "source": [
        "Para preprocesarva, vamos a:\n",
        "- Leer imágenes de disco.\n",
        "- Decodificar contenido y convertirlo en RGB.\n",
        "- Convertir valores de enteros a coma flotante (float).\n",
        "- Reescalado a valores entre 0 y 1 (mejor para redes neuronales, esto previene posibles overflows al multiplicar por pesos).\n",
        "\n",
        "Todas las operacfiones anteriores las realiza la clase `ImageDataGenerator` del paquete `tf.keras`. Lee las imágenes y las almacena en arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbKVMUaBA14w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVOP4BOcL57E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's resize images to this size\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEYTv3G6L9I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rescale the pixel values to range between 0 and 1\n",
        "train_generator = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmM-kS68L-iY",
        "colab_type": "text"
      },
      "source": [
        "After defining the generators for training and validation images, the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff0NXGJEVPWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32 # Read a batch of 64 images at each step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zenaWVaHL_jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbgDJgcUMAeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = val_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h77qZjn2MFaZ",
        "colab_type": "text"
      },
      "source": [
        "## Usamos generators para mostrar algunas imágenes y sus etiquetas\n",
        "\n",
        "Next, we will extract a batch of images from the training generator, then plot several of them with `matplotlib`. The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is the pixel values and y_train is the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRkntEZ1MJev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, labels_batch = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFItkxNsp1EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The shape will be (32, 150, 150, 3)\n",
        "# This means a list of 32 images, each of which is 150x150x3.\n",
        "# The 3 at the end refers to the R,G,B color channels.\n",
        "# A grayscale image would be (for example) 150x150x1\n",
        "print(image_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6sb2tmtqEYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The shape (32,) means a list of 64 numbers\n",
        "# each of these will either be 0 or 1\n",
        "print(labels_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4iqLgMjMMWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images returned by the generator\n",
        "# in a grid with 1 row and 5 columns\n",
        "def plot_images(images):\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images, axes):\n",
        "      ax.imshow(img)\n",
        "      ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQUpgA1bMOti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_images(image_batch[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnj3jfpvTlih",
        "colab_type": "text"
      },
      "source": [
        "Next, let's retrieve the labels. All images will be labeled either 0 or 1, since this is a binary classification problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq1rm3jTTa9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here are the first 5 labels from the dataset\n",
        "# that correspond to the images above\n",
        "print(labels_batch[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMd_qHITcxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, we can see that \"0\" maps to cat,\n",
        "# and \"1\" maps to dog\n",
        "print(train_data_gen.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yukXvCdWMSDj",
        "colab_type": "text"
      },
      "source": [
        "## Crear modelo\n",
        "El modelo tiene 3 capas convolucionales con max pooling. Hay al final una capa completamente conectada con 256 unidades. la salida es 0 ó 1 con una función de activación sigmoid. Si cerca de 1, es un perro, si no, es un gato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAvbO8Q2BEN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dd4nHoIMGy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', \n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN8hv9ItMXNr",
        "colab_type": "text"
      },
      "source": [
        "Compilamos el modelo, y seleccionamos el optimizador Adam para el descenso de gradientes, y binary cross entropy para la función de pérdidas (cross entropy mide aproximadamente la distancia entre la predicción de la red y la que querríamos que tuviera)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sarE21oqMYgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB2GwR_EMZwm",
        "colab_type": "text"
      },
      "source": [
        "Vemos un resumen con el método `summary`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mgFrgh-MbL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGviR2YtBq_H",
        "colab_type": "text"
      },
      "source": [
        "Notar que este modelo tiene 5M de parámetros (ó pesos). El modelo está listo para entrenar, usando las salidas de antes de `ImagedataGenerator`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx6po3HfMcTu",
        "colab_type": "text"
      },
      "source": [
        "## Entrenar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmEm3VVwMeRg",
        "colab_type": "text"
      },
      "source": [
        "Use the `fit` method to train the network. You will train the model for 15 epochs (an epoch is one \"sweep\" over the training set, where each image is used once to perform a round of gradient descent, and update the models parameters). This will take one to two minutes, so let's start it now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ggEXVPWcxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe5gKJ6eMfNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSjVPgaZ1bLn",
        "colab_type": "text"
      },
      "source": [
        "Inside `model.fit`, TensorFlow uses gradient descent to find useful values for all the weights in the model. When you create the model, the weights are initialized randomly, then gradually improved over time. The data generator is used to load batches of data off disk. Then, for each batch:\n",
        "- The model performs a forward pass (the images are classified by the network).\n",
        "- Then, the model performs a backward pass (the error is computed, then each weight is slightly adjusted using gradient descent to improve the accuracy on the next iteration).\n",
        "\n",
        "Gradient descent is an iterative process. The longer you train the model, the more accurate it will become on the training set. But, the more likely it is to overfit! Meaning, the model will begin to memorize the training images, rather than learn patterns that enable it generalize to new images not included in the training set. \n",
        "\n",
        "- We can see whether overfitting is present by comparing the accuracy on the training and validation data.\n",
        "\n",
        "If you look at the accuracy figures reported above, you should see that training accuracy is over 90%, while validation accuracy is only around 70%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIYFh3m9MpvG",
        "colab_type": "text"
      },
      "source": [
        "## Comprobar overfitting\n",
        "El precisión en el set de validación es importante: it helps you estimate how well our model is likely to work on new, unseen data in the future. To see how much overfitting is present (and when it occurs), we will create two plots, one for accuracy, and another for loss. Roughly, loss (or error) is the inverse of accuracy (lower is better). Unlike accuracy, loss takes the confidence of a prediction into account (a confidently wrong predicitions has a higher loss than one that is only slightly wrong)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1ZuxB7iMrBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBooB9-bpht",
        "colab_type": "text"
      },
      "source": [
        "Overfitting occurs when the validation loss stops decreasing. In this case, that occurs around epoch 5 (give or take). Your results may be slightly different each time you run this code (since the weights are initialized randomly).\n",
        "\n",
        "Why does overfitting happen? When there are only a \"small\" number of training examples, the model sometimes learns from noises or unwanted details, to an extent that it negatively impacts the performance of the model on new examples. It means that the model will have a difficult time \"generalizing\" on a new dataset (making accurate predictions on images that weren't included in the training set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3hfnxDST1we",
        "colab_type": "text"
      },
      "source": [
        "# Optional: reducir overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-TD-ium4LJL",
        "colab_type": "text"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "In this exercise, you will use data augmentation and dropout to improve your model. Follow along by reading and running the code below. There are two **TODOs** for you to complete, and a solution is given below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFrRJObuMv8d",
        "colab_type": "text"
      },
      "source": [
        "## Data augmentation\n",
        "Overfitting occurs when there are a \"small\" number of training examples. One way to fix this problem is to increase the size of the training set, by gathering more data (the larger and more diverse the dataset, the better!)\n",
        "\n",
        "We can also use a technique called \"data augmentation\" to increase the size of the training set, by generating new examples from existing ones by applying random transformations (for example, rotation) that yield believable-looking images. \n",
        "\n",
        "This is especially effective when working with images. For example, our training set may only contain images of cats that are right side up. If our validation set contains images of cats that are upside down, our model may have trouble classifying them correctly. To help teach it that cats can appear in any orientation, we will randomly rotate images from our training set during training. This helps expose the model to more aspects of the data, and can lead to better generalization.\n",
        "\n",
        "Data augmentation is built into the ImageDataGenerator. You can specifiy different transformations, and it will take care of applying then during the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIWUljgzb5dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create new data generators, this time with \n",
        "# data augmentation enabled\n",
        "train_generator = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLl4-mjKb-vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_generator.flow_from_directory(batch_size=32,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXaXALsZ5CST",
        "colab_type": "text"
      },
      "source": [
        "The next cell will show how the same training image appears when used with five different types of data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtLNwy9_b_RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plot_images(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsKX1NNpchmM",
        "colab_type": "text"
      },
      "source": [
        "We only apply data augmentation to the training examples, so our validation generator looks the same as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZjPRpJkchwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_generator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQIyYxvAcknP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = val_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-s-DCjFcm1N",
        "colab_type": "text"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K34kcZfzco5M",
        "colab_type": "text"
      },
      "source": [
        "Another technique to reduce overfitting is to introduce dropout to the network. Dropout is a form of regularization that makes it more difficult for the network to memorize rare details (instead, it is forced to learn more general patterns).\n",
        "\n",
        "When you apply dropout to a layer it randomly drops out (set to zero) a number of activations during training. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "When appling 0.1 dropout to a certain layer, it randomly deactivates 10% of the output units in each training epoch.\n",
        "\n",
        "Create a new model using Dropout. You'll reuse the model definition from above, and add a Dropout layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW2NXkclDxo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3e7ir-HcnZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Your code here\n",
        "# Create a new CNN that takes advantage of Dropout.\n",
        "# 1) Reuse the model declared in tutorial above.\n",
        "# 2) Add a new line that says \"Dropout(0.2),\" immediately\n",
        "# before the line that says \"Flatten()\"."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hmzYnem6TEf",
        "colab_type": "text"
      },
      "source": [
        "## Solution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnRSZBV86dy7",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', \n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlmQwrwcu4V",
        "colab_type": "text"
      },
      "source": [
        "After introducing dropout to the network, compile your model and view the layers summary. You should see a Dropout layer right before flatten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L77Pt-WFcxYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEMGlbwWc254",
        "colab_type": "text"
      },
      "source": [
        "## Train your new model\n",
        "Add code to train your new model. Previously, we trained for 15 epochs. You will need to train this new modek for more epochs, as data augmentation and dropout make it more difficult for a CNN to memorize the training data (this is what we want!).\n",
        "\n",
        "Here, you'll train this model for 25 epochs. This may take a few minutes, and you may need to train it for longer to reach peak accuracy. If you like, you can continue experimenting with that at home."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jLoyPTRc2Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BnRJWB164DY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: your code here\n",
        "# Add code to call model.fit, using your new\n",
        "# data generators with image augmentation\n",
        "# For reference, see the \"Train the model\"\n",
        "# section above"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n0HeqPt6_-1",
        "colab_type": "text"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSwPqgkM7BU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ktPjfbdCoC",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate your new model\n",
        "Finally, let's again create plots of accuracy and loss (we use these plots often in practice!) Now, compare the loss and accuracy curves for the training and validation data. Were you able to achieve a higher validation accuracy than before? Note that even this model will eventually overfit. To prevent that, we use a technique called early stopping (we stop training when the validation loss is no longer decreasing). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ma9lDmidMWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "redes_convolucionales.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}