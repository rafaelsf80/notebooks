{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoML Tables Quick Start v1.4 - external Colab [MAKE A COPY].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m26YhtBMvVWA"
      },
      "source": [
        "# \"AutoML tables\"\n",
        "> (SPANISH) Entrenamiento e inferencia con Google Cloud AutoML Tables\n",
        "\n",
        "\n",
        "- toc: true \n",
        "- badges: true \n",
        "- comments: true\n",
        "- categories: [\"Structured Data\"]\n",
        "- image: images/googlecloud.png\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b--5FDDwCG9C"
      },
      "source": [
        "## 1. Project set up\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AZs0ICgy4jkQ"
      },
      "source": [
        "Follow the [AutoML Tables documentation](https://cloud.google.com/automl-tables/docs/) to\n",
        "* Create a Google Cloud Platform (GCP) project.\n",
        "* Enable billing.\n",
        "* Apply to whitelist your project.\n",
        "* Enable AutoML API.\n",
        "* Enable AutoML Talbes API.\n",
        "* Create a service account, grant required permissions, and download the service account private key.\n",
        "\n",
        "You also need to upload your data into Google Cloud Storage (GCS) or BigQuery. For example, to use GCS as your data source\n",
        "* Create a GCS bucket.\n",
        "* Upload the training and batch prediction files.\n",
        "\n",
        "\n",
        "**Warning:** Private keys must be kept secret. If you expose your private key it is recommended to revoke it immediately from the Google Cloud Console."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xZECt1oL429r"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rstRPH9SyZj_"
      },
      "source": [
        "## 2. Initialize and authenticate\n",
        "This section runs intialization and authentication. It creates an authenticated session which is required for running any of the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BR0POq2UzE7e"
      },
      "source": [
        "### Install the client library\n",
        "Run the following cell. Click on the 'Choose Files' button and select the client library compressed file. The file is uploaded to your Colab and installed using `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43aXKjDRt_qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Install AutoML Tables client library { vertical-output: true }\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from google.colab import files\n",
        "import tarfile\n",
        "\n",
        "# Upload the client library\n",
        "compressed_file_upload = files.upload()\n",
        "compressed_file_name = list(compressed_file_upload.keys())[0]\n",
        "# Decompress the client library\n",
        "with tarfile.open(compressed_file_name) as tar:\n",
        "  tar.extractall(path='.')\n",
        "# Install the client library\n",
        "!pip install ./python/automl-v1beta1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eVFsPPEociwF"
      },
      "source": [
        "### Authenticate using service account key\n",
        "Run the following cell. Click on the 'Choose Files' button and select the service account private key file. If your Service Account key file or folder is hidden, you can reveal it in a Mac by pressing the <b>Command + Shift + .</b> combo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-kCqysAuaJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Authenticate using service account key and create a client. { vertical-output: true }\n",
        "\n",
        "from google.cloud import automl_v1beta1\n",
        "\n",
        "# Upload service account key\n",
        "keyfile_upload = files.upload()\n",
        "keyfile_name = list(keyfile_upload.keys())[0]\n",
        "# Authenticate and create an AutoML client.\n",
        "client = automl_v1beta1.AutoMlClient.from_service_account_file(keyfile_name)\n",
        "# Authenticate and create a prediction service client.\n",
        "prediction_client = automl_v1beta1.PredictionServiceClient.from_service_account_file(keyfile_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s3F2xbEJdDvN"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uX4aJYUiXh5",
        "colab_type": "text"
      },
      "source": [
        "Enter your GCP project ID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6R4h5HF1Dtds",
        "colab": {}
      },
      "source": [
        "#@title GCP project ID and location\n",
        "\n",
        "project_id = '<PROJECT_ID>' #@param {type:'string'}\n",
        "location = 'us-central1'\n",
        "location_path = client.location_path(project_id, location)\n",
        "location_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rUlBcZ3OfWcJ"
      },
      "source": [
        "To test whether your project set up and authentication steps were successful, run the following cell to list your datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "sf32nKXIqYje",
        "colab": {}
      },
      "source": [
        "#@title List datasets. { vertical-output: true }\n",
        "\n",
        "list_datasets_response = client.list_datasets(location_path)\n",
        "datasets = {dataset.display_name: dataset.name for dataset in list_datasets_response}\n",
        "datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9uE8MvMkOPd"
      },
      "source": [
        "You can also print the list of your models by running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "j4-bYRSWj7xk",
        "colab": {}
      },
      "source": [
        "#@title List models. { vertical-output: true }\n",
        "\n",
        "list_models_response = client.list_models(location_path)\n",
        "models = {model.display_name: model.name for model in list_models_response}\n",
        "models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qozQWMnOu48y"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ODt86YuVDZzm"
      },
      "source": [
        "## 3. Import training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XwjZc9Q62Fm5"
      },
      "source": [
        "### Create dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_JfZFGSceyE_"
      },
      "source": [
        "Select a dataset display name and pass your table source information to create a new dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_JErW3cw-0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Create dataset { vertical-output: true, output-height: 200 }\n",
        "\n",
        "dataset_display_name = 'iris_dataset' #@param {type: 'string'}\n",
        "\n",
        "create_dataset_response = client.create_dataset(\n",
        "    location_path,\n",
        "    {'display_name': dataset_display_name, 'tables_dataset_metadata': {}})\n",
        "dataset_name = create_dataset_response.name\n",
        "create_dataset_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35YZ9dy34VqJ"
      },
      "source": [
        "### Import data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3c0o15gVREAw"
      },
      "source": [
        "You can import your data to AutoML Tables from GCS or BigQuery. For this tutorial, you can use the [iris dataset](https://storage.cloud.google.com/rostam-193618-tutorial/automl-tables-v1beta1/iris.csv) as your training data. You can create a GCS bucket and upload the  data into your bucket. The URI for your file is `gs://BUCKET_NAME/FOLDER_NAME1/FOLDER_NAME2/.../FILE_NAME`. Alternatively you can create a BigQuery table and upload the data into the table. The URI for your table is `bq://PROJECT_ID.DATASET_ID.TABLE_ID`.\n",
        "\n",
        "Importing data may take a few minutes or hours depending on the size of your data. If your Colab times out, run the following command to retrieve your dataset. Replace `dataset_name` with its actual value obtained in the preceding cells.\n",
        "\n",
        "    dataset = client.get_dataset(dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIWlq3NTYhOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title ... if data source is GCS { vertical-output: true }\n",
        "\n",
        "dataset_gcs_input_uris = ['gs://<BUCKET_NAME>/<FILE_PATH>',] #@param\n",
        "# Define input configuration.\n",
        "input_config = {\n",
        "    'gcs_source': {\n",
        "        'input_uris': dataset_gcs_input_uris\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB_GdeqCJW5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title ... if data source is BigQuery { vertical-output: true }\n",
        "\n",
        "dataset_bq_input_uri = 'bq://<PROJECT_ID>.<DATASET_NAME>.<TABLE_NAME>' #@param {type: 'string'}\n",
        "# Define input configuration.\n",
        "input_config = {\n",
        "    'bigquery_source': {\n",
        "        'input_uri': dataset_bq_input_uri\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNVYfpoXJsNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #@title Import data { vertical-output: true }\n",
        "\n",
        "import_data_response = client.import_data(dataset_name, input_config)\n",
        "print('Dataset import operation: {}'.format(import_data_response.operation))\n",
        "# Wait until import is done.\n",
        "import_data_result = import_data_response.result()\n",
        "import_data_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdxBI4s44ZRI",
        "colab_type": "text"
      },
      "source": [
        "### Review the specs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC0PWKqH4jwr",
        "colab_type": "text"
      },
      "source": [
        "Run the following command to see table specs such as row count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Vzq_gwXxo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Table schema { vertical-output: true }\n",
        "\n",
        "import google.cloud.automl_v1beta1.proto.data_types_pb2 as data_types\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List table specs\n",
        "list_table_specs_response = client.list_table_specs(dataset_name)\n",
        "table_specs = [s for s in list_table_specs_response]\n",
        "# List column specs\n",
        "table_spec_name = table_specs[0].name\n",
        "list_column_specs_response = client.list_column_specs(table_spec_name)\n",
        "column_specs = {s.display_name: s for s in list_column_specs_response}\n",
        "# Table schema pie chart.\n",
        "type_counts = {}\n",
        "for column_spec in column_specs.values():\n",
        "  type_name = data_types.TypeCode.Name(column_spec.data_type.type_code)\n",
        "  type_counts[type_name] = type_counts.get(type_name, 0) + 1\n",
        "\n",
        "plt.pie(x=type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%')\n",
        "plt.axis('equal')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcJP7xoq4yAJ",
        "colab_type": "text"
      },
      "source": [
        "Run the following command to see column specs such inferred schema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNykW_YOYt6d",
        "colab_type": "text"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kNRVJqVOL8h3"
      },
      "source": [
        "## 4. Update dataset: assign a label column and enable nullable columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-57gehId9PQ5"
      },
      "source": [
        "AutoML Tables automatically detects your data column type. For example, for the [Iris dataset](https://storage.cloud.google.com/rostam-193618-tutorial/automl-tables-v1beta1/iris.csv) it detects `species` to be categorical and `petal_length`, `petal_width`, `sepal_length`, and `sepal_width` to be numerical. Depending on the type of your label column, AutoML Tables chooses to run a classification or regression model. If your label column contains only numerical values, but they represent categories, change your label column type to categorical by updating your schema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRqdQ7Xiq04x",
        "colab_type": "text"
      },
      "source": [
        "### Update a column: set to nullable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCEUIPKegWrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Update dataset { vertical-output: true }\n",
        "\n",
        "update_column_spec_dict = {\n",
        "    'name': column_specs['sepal_length'].name,\n",
        "    'data_type': {\n",
        "        'type_code': 'FLOAT64',\n",
        "        'nullable': True\n",
        "    }\n",
        "}\n",
        "update_column_response = client.update_column_spec(update_column_spec_dict)\n",
        "update_column_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUqKi3tkqrgW",
        "colab_type": "text"
      },
      "source": [
        "**Tip:** You can use `'type_code': 'CATEGORY'` in the preceding `update_column_spec_dict` to convert the column data type from `FLOAT64` `to `CATEGORY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nDMH_chybe4w"
      },
      "source": [
        "### Update dataset: assign a label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVIruWg0u33t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Update dataset { vertical-output: true }\n",
        "\n",
        "label_column_name = 'species' #@param {type: 'string'}\n",
        "label_column_spec = column_specs[label_column_name]\n",
        "label_column_id = label_column_spec.name.rsplit('/', 1)[-1]\n",
        "print('Label column ID: {}'.format(label_column_id))\n",
        "# Define the values of the fields to be updated.\n",
        "update_dataset_dict = {\n",
        "    'name': dataset_name,\n",
        "    'tables_dataset_metadata': {\n",
        "        'target_column_spec_id': label_column_id\n",
        "    }\n",
        "}\n",
        "update_dataset_response = client.update_dataset(update_dataset_dict)\n",
        "update_dataset_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z23NITLrcxmi",
        "colab_type": "text"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FcKgvj1-Tbgj"
      },
      "source": [
        "## 5. Creating a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pnlk8vdQlO_k"
      },
      "source": [
        "### Train a model\n",
        "Specify the duration of the training. For example, `'train_budget_milli_node_hours': 1000` runs the training for one hour. If your Colab times out, use `client.list_models(location_path)` to check whether your model has been created. Then use model name to continue to the next steps. Run the following command to retrieve your model. Replace `model_name` with its actual value.\n",
        "\n",
        "    model = client.get_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11izNd6Fu37N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Create model { vertical-output: true }\n",
        "\n",
        "model_display_name = 'iris_model' #@param {type:'string'}\n",
        "\n",
        "model_dict = {\n",
        "    'display_name': model_display_name,\n",
        "    'dataset_id': dataset_name.rsplit('/', 1)[-1],\n",
        "    'tables_model_metadata': {'train_budget_milli_node_hours': 1000}\n",
        "}\n",
        "create_model_response = client.create_model(location_path, model_dict)\n",
        "print('Dataset import operation: {}'.format(create_model_response.operation))\n",
        "# Wait until model training is done.\n",
        "create_model_result = create_model_response.result()\n",
        "model_name = create_model_result.name\n",
        "create_model_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wS1is9IY5nK",
        "colab_type": "text"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LMYmHSiCE8om"
      },
      "source": [
        "## 6. Make a prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2WVbMFll96k",
        "colab_type": "text"
      },
      "source": [
        "There are two different prediction modes: online and batch. The following cell shows you how to make an online prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt-KXEEQu3-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Make an online prediction { vertical-output: true }\n",
        "\n",
        "sepal_length = 5.8 #@param {type:'slider', min:4, max:8, step:0.1}\n",
        "sepal_width = 3.1 #@param {type:'slider', min:2, max:5, step:0.1}\n",
        "petal_length = 3.8 #@param {type:'slider', min:1, max:7, step:0.1}\n",
        "petal_width = 1.2 #@param {type:'slider', min:0, max:3, step:0.1}\n",
        "payload = {\n",
        "    'row': {       \n",
        "        'values': [\n",
        "            {'number_value': sepal_length},\n",
        "            {'number_value': sepal_width},\n",
        "            {'number_value': petal_length},\n",
        "            {'number_value': petal_width}\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "# Make a prediction.\n",
        "prediction_client.predict(model_name, payload)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtk00NP1sNMg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TarOq84-GXch"
      },
      "source": [
        "## 7. Batch prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Soy5OB8Wbp_R"
      },
      "source": [
        "### Initialize prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "39bIGjIlau5a"
      },
      "source": [
        "Your data source for batch prediction can be GCS or BigQuery. For this tutorial, you can use [iris_batch_prediction_input.csv](https://storage.cloud.google.com/rostam-193618-tutorial/automl-tables-v1beta1/iris_batch_prediction_input.csv) as input source. Create a GCS bucket and upload the file into your bucket. Some of the lines in the batch prediction input file are intentionally left missing some values. The AutoML Tables logs the errors in the `errors.csv` file.\n",
        "\n",
        "**NOTE:** The client library has a bug. If the following cell returns a `TypeError: Could not convert Any to BatchPredictResult` error, ignore it. The batch prediction output file(s) will be updated to the GCS bucket that you set in the preceding cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkF3bH0qu4DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Start batch prediction { vertical-output: true, output-height: 200 }\n",
        "\n",
        "batch_predict_gcs_input_uris = ['gs://automl-tables-data/iris_batch_prediction_input.csv',] #@param\n",
        "batch_predict_gcs_output_uri_prefix = 'gs://automl-tables-pred' #@param {type:'string'}\n",
        "# Define input source.\n",
        "batch_prediction_input_source = {\n",
        "  'gcs_source': {\n",
        "    'input_uris': batch_predict_gcs_input_uris\n",
        "  }\n",
        "}\n",
        "# Define output target.\n",
        "batch_prediction_output_target = {\n",
        "    'gcs_destination': {\n",
        "      'output_uri_prefix': batch_predict_gcs_output_uri_prefix\n",
        "    }\n",
        "}\n",
        "batch_predict_response = prediction_client.batch_predict(\n",
        "    model_name, batch_prediction_input_source, batch_prediction_output_target)\n",
        "print('Batch prediction operation: {}'.format(batch_predict_response.operation))\n",
        "# Wait until batch prediction is done.\n",
        "batch_predict_result = batch_predict_response.result()\n",
        "batch_predict_response.metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVJhh_k0PfxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_predict_response.metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nr5q2M8W2VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}